<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Nicholas Jennings - Computational Media Portfolio</title>
    <link rel="stylesheet" href="styles.css">
    <!-- For Android (Chrome) -->
    <meta name="theme-color" content="#90D7FF"> <!-- Set this to the blue color of your header -->

    <!-- For iOS (Safari) -->
    <meta name="apple-mobile-web-app-status-bar-style" content="default">
    <meta name="apple-mobile-web-app-capable" content="yes">
</head>
<body id="research">

    <div class="flower-container">
        <div class="flower-mask" style="transform: translate(-90%, -80%) rotate(115deg); width: 1000px; height: 1000px;"></div>
        <div class="flower-mask" style="transform: translate(-8%, -20%) rotate(-9deg); width: 1500px; height: 1500px;"></div>
    </div>
        <!-- <div class="flower-mask" style="transform: translate(0%, 0%) rotate(-5deg); width: 2000px; height: 2000px;"></div> -->

    <header>
        <div class="faceHead">
            <h1>Nicholas Jennings</h1>
            <div class="face-container">
                <img src="images/faces/faceClean.png" class = "face active">
                <img src="images/faces/faceBeard.png" class = "face">
                <img src="images/faces/faceVR.png" class = "face">
                <img src="images/faces/faceWiz.png" class = "face">
            </div>
        </div>
        <nav>
            <a href="index.html">Home</a>
            <a href="research.html">Research</a>
            <a href="projects.html">Projects</a>
        </nav>
    </header>
    <script src="script.js"></script>
    <section id="research">
        <h2 class="section-title">Computational Media Portfolio</h2>
        <p>
            The following is a selection of my portfolio for UCSC computational media (technical focus). You can look at the rest of this website to see all other projects/research.
        </p>

        <h3>Technical (Focus)</h3>
        <div class="project">
            <div class="project-photo-container">
                <img src="images/RIT.png" class="project-photo" style="border-radius: 8%;">
            </div>
            
            <div class="project-content">
                <h3 class="project-title">GROMIT</h3>
                <p class="project-description">
                    GROMIT is an at-runtime behvaior generation system for video games, made for my first-authored paper "What's the Game, then? Opportunities and Challenges for Runtime Behavior Generation" (Published at UIST'24, Best Paper).
                    When triggered by a user action, GROMIT generates new behaviors by writing c# code, which is compiled at runtime and incorperated
                    into the game. The first half of the Research Paper gives a technical overview of the system, and the paper's video figure (accessed through the 'Research Paper' link below) shows all 3 demos.
                    I built the majority of the system, except for the RAG memory system, some prompt engineering, and the traffic demo scene.
                    The libraries and assets used are listed on the github repo. 
                    
                    <br>The repo is the open-source version of the project, so doesn't contain
                    some paid assets from the paper(e.g. the traffic scene) and is missing the OpenAI API keys. To run the project, download the repo, open it in Unity, go to 
                    the desired scene (e.g. dungeon1) and paste your api key into the "Custom GPT" component of the managers gameobject. Watch the 'Repo Setup Video' below for more details.
                </p>
                <a href="https://github.com/NicholasJJ/GROMIT" class="paper-link">Repo</a>
                <a href="https://youtu.be/w78XQchaQDU" class="paper-link">Repo setup video</a>
                <a href="https://dl.acm.org/doi/10.1145/3654777.3676358" class="paper-link">Research Paper</a>
                <a href="https://youtu.be/76sMtx_0aKU" class="paper-link">Research Paper Video Figure</a>
            </div>
        </div>

        <div class="project">
            <div class="project-photo-container">
                <img src="images/Figure-1a-update.png" class="project-photo" style="border-radius: 8%;">
            </div>
            
            <div class="project-content">
                <h3 class="project-title">GeneratiVR</h3>
                <p class="project-description">
                    GeneratiVR is a VR frontend to a Generative Design system that runs on Grasshopper (A generative design CAD enviroment). Users explore a set of shelf designs, and can
                    use several VR techniques to refine their search for shelves they like. They then select a set of shelves, which is returned to the Greasshopper system which generates a next interation of shelves.
                    I was a lead developer on all the UI tools for the system, and had a minor role in integrating the VR portion with Grasshopper.

                    <br>I can't make the repository public, but I've included an apk for the VR portion of the system. If you have a Meta Quest headset you can install the apk using the <a href="https://sidequestvr.com/download">Advanced Installer SideQuest App</a>
                    Also linked are the two research papers that came out of the project. The first
                    is a Late-Breaking work that focuses on the system itself, and the second includes a study comparing the VR interface with a 2D version.
                </p>
                <a href="https://drive.google.com/drive/folders/1Ugg_FN6hif7M0fy8qLu6v_trRpegE7PG?usp=sharing" class="project-link">APK Download</a>
                <a href="https://dl.acm.org/doi/abs/10.1145/3491101.3519616" class="project-link">GeneratiVR Paper</a>
                <a href="https://www.cambridge.org/core/journals/proceedings-of-the-design-society/article/vr-or-not-investigating-interface-type-and-user-strategies-for-interactive-design-space-exploration/BFA6CE13915DD825D04B70806CCB70A3" class="project-link">VR or Not? Paper</a>
                <a href="https://www.youtube.com/watch?v=qHSx5f6fRts" class="project-link">Video</a>
            </div>
        </div>

        <div class="project">
            <div class="project-photo-container">
                <img src="images/XRSignifiersTeaser.png" class="project-photo" style="border-radius: 8%;">
            </div>
            
            <div class="project-content">
                <h3 class="project-title">VR Signifiers</h3>
                <p class="project-description">
                    This project was a collection of VR interaction techniques used for a research project on VR signifiers.
                    In the study, participants were given the VR techniques in a series and asked to complete a task for each one. The performance of each
                    technique could then be compared.<br>
                    I was the sole technical contributer to this project, although two of the interaction techniques (GoGo and Seven League Boots) are recreations of popular existing interation techniques, and the usability tests are based on similar tests in prior work.
                    The paper for this project is a work-in-progress, but the system and study are finished.<br> I can't make the repository public, but in the linked google drive you'll find
                    an APK file for each of the two task types, along with instructions on the controls for each task.
                </p>
                <a href="https://youtu.be/TCjI7QQ696k" class="project-link">Video Figure</a>
                <a href="https://drive.google.com/drive/folders/1z18jsi-K56wQ17xLVF6bXCn3zohwIf7-?usp=drive_link" class="project-link">APK Downloads</a>
            </div>
        </div>

        <h3>Creative</h3>
        <div class="project">
            <div class="project-photo-container">
                <img src="images/minotaur.png" class="project-photo" style="border-radius: 8%;">
            </div>
            
            <div class="project-content">
                <h3 class="project-title">Minotaur</h3>
                <p class="project-description">
                    A short adventure game about the myth of Theseus and the Minotaur. It has procedural runtime maze generation, wall-walking, a full dialog system, and spooky vibes! Made for a breadth class on greek myths.
                </p>
                <a href="https://frackfrick.itch.io/minotaur" class="pproject-link">Play it on itch.io</a>
                <a href="https://youtu.be/PRGTBNITc2A" class="pproject-link">Video Walkthrough</a>
            </div>
        </div>

        <h3>Interpretive</h3>
        <div class="project">
            <div class="project-photo-container">
                <img src="images/RIT.png" alt="Pseudo-Isochromatic dot plate" class="project-photo" style="border-radius: 8%;">
            </div>
            
            <div class="project-content">
                <h3 class="project-title">What's the Game, then?</h3>
                <p class="project-description">
                    The second half of the paper "What's the Game, then? Opportunities and Challenges for Runtime Behavior Generation", beginning in section 5, contains results of interviews with game developers
                    about the system in the paper, and about Generative-AI based runtime generation in general.
                </p>
                <a href="https://dl.acm.org/doi/10.1145/3654777.3676358" class="paper-link">Research Paper</a>
                <a href="https://youtu.be/76sMtx_0aKU" class="paper-link">Research Paper Video Figure</a>
            </div>
        </div>
    </section>

    
</body>
</html>
